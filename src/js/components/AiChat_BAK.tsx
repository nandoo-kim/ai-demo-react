import React, { useEffect, useRef, useState } from "react";
import { HumanMessage, SystemMessage } from '@langchain/core/messages'
import axios from "axios";
import ninegrid from "ninegrid2";

import '/public/css/aiChat.css';
//import * as dotenv from "dotenv";
import { ChatOpenAI } from '@langchain/openai';
import { BufferMemory } from "langchain/memory";
import { ConversationChain } from "langchain/chains";
import { loadSummarizationChain } from "langchain/chains";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";


//import { Ollama } from "langchain/llms/ollama";
//import { Ollama } from 'langchain/llms/ollama';
import { ChatOllama } from "@langchain/ollama";
import { Ollama } from "@langchain/ollama";
import { StringOutputParser } from "@langchain/core/output_parsers"
import {ChatPromptTemplate, PromptTemplate} from "@langchain/core/prompts"
//import danfojs-node from "danfojs-node";
//import { createStructuredOutputAgent } from "langchain/agents";
//const dfd = require("danfojs-node");

import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
//import { HumanMessage } from "@langchain/core/messages";
import { QdrantVectorStore } from "@langchain/qdrant";
import { QdrantClient } from "@qdrant/js-client-rest";
//import { OllamaEmbeddings } from "@langchain/community/embeddings/ollama";
import { OllamaEmbeddings } from "@langchain/ollama";

// Qdrant í´ë¼ì´ì–¸íŠ¸ ìƒì„±



const AiChat: React.FC = () => {

	//const qdrant = null;//new QdrantClient({ url: "http://localhost:6333" });

	const qdrantClient = new QdrantClient({ url: "http://localhost:6333" });

	const setupQdrant = async () => {
		const collections = await qdrantClient.getCollections();
		const collectionNames = collections.collections.map(c => c.name);

		if (!collectionNames.includes("my_collection")) {
			await qdrantClient.createCollection("my_collection", {
				vectors: { size: 768, distance: "Cosine" }
			});

			console.log("âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ");
		} else {
			console.log("â„¹ï¸ ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.");
		}
	};

	setupQdrant();


	const isJSON = (obj)=> {
		return obj instanceof Object && !Array.isArray(obj);
	}
	const parseResponse = (resp) => {

		console.log(resp);

		let respText;

		if (isJSON(resp)) {		//gemini
			respText = resp.text;
		}
		else {
			respText = resp;
		}

		if (respText.startsWith("```json")) {
			respText = respText.replace("```json", "");
			const idx = respText.indexOf("```");
			if (idx > 0) {
				respText = respText.substring(0, idx);
				console.log(respText.substring(idx+3));
			}
		}


		console.log(respText);

		//const parsed = JSON.parse(resp.content);
		return JSON.parse(respText);
	};

	const chunkContext = () => {

		let contexts = [];

		const data = document.querySelector("nine-grid").data.get();
		let lineContext = "";
		for (let o of data) {

			const line = `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;

			if (line.length + lineContext.length > 1000) {

				contexts.push(lineContext);
				lineContext = line;
			}
			else {
				lineContext += line;
			}
		}

		contexts.push(lineContext);

		//console.log(contexts.length, contexts);

		return contexts;
	}
	const chunkContext2 = () => {

		let contexts = [];

		const title = `ë¬¸ì„œID\të¬¸ì„œëª…\të§¤ì¶œì•¡\tìˆ˜ì •ì\tìˆ˜ì •ì¼\n`;
		const data = document.querySelector("nine-grid").data.get();
		let lineContext = "";
		for (let o of data) {

			//const line = `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
			const line = `${o.doc_id}\t${o.doc_nm}\t${o.amt}\t${o.update_user}\t${o.update_dt}\n`;

			if (line.length + lineContext.length > 1000) {

				contexts.push(title + lineContext);
				lineContext = line;
			}
			else {
				lineContext += line;
			}
		}

		contexts.push(title + lineContext);

		//console.log(contexts.length, contexts);

		return contexts;
	}

	const extractJson = (arr, properties) => {

		try {


			console.log(arr, properties);

			if (!Array.isArray(properties)) {
				properties = properties?.split(",");
			}

			//console.log(properties);

			const extractJson2 = (arr, properties) => {

				if (!arr || typeof arr !== "object") return [];

				return Object.entries(arr)
					.flatMap(([key, value]) => {
						if (Array.isArray(value)) {
							return value.filter(item =>
								item && typeof item === "object" &&
								properties.every(prop => prop in item && item[prop] !== null) // âœ… `null` ê°’ í•„í„°ë§ ì¶”ê°€
							);
						} else if (typeof value === "object") {
							return extractJson2(value, properties);
						} else {
							return properties.includes(key) ? [arr] : [];
						}
					});
			};

			//console.log(Array.isArray(arr) ? arr.flatMap(o => extractJson2(o, properties)) : extractJson2(arr, properties));
			return Array.isArray(arr) ? arr.flatMap(o => extractJson2(o, properties)) : extractJson2(arr, properties);
		} catch (e) {
			console.log(e);
			//ninegrid.alert(e);
			chatRef.current.add("ai", e);
			//ninegrid.alert(e, null, {"class": "rgb", "animation": "shake", });
		}
	};



	const aiSearch = async (question:string) => {

		try {

			/**
			const d = {
				amt: null,
				doc_id: 63,
				doc_nm: "aaa"
			}

			console.log(extractJson(d, "doc_id,doc_nm"));
			return;
				*/

			//const textQ = textAreaRef.current.value;

			if (question == "") return "";

			/**
			let listQuestion = [];

			//console.log("--------------");
			for (let context of chunkContext()) {

				const aa = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'context'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'question'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë¼ì¸ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì°¾ìœ¼ì„¸ìš”. ì°¾ì€ ì •ë³´ë§Œ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ { comment: ë„ˆì˜ ì˜ê²¬, data: [ { doc_id: 1, doc_nm: "", amt: "", update_user: "", update_dt: "" } ] ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${question}\n\ncontext:\n` + context;
				//console.log("==========", aa);
				listQuestion.push(aa);
				//listQuestion.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë§Œì•½, ê´€ë ¨ë¬¸ì„œê°€ ì—†ìœ¼ë©´ 'ê´€ë ¨ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”. ì°¾ì€ ë¬¸ì„œì •ë³´ëŠ” ë‚´ê°€ ë³´ë‚¸ í˜•ì‹ ê·¸ëŒ€ë¡œ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜. { data: JSON Array }}. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${question}\n\ncontext: ${context}`);
				//listQuestion.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'context'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'question'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë¼ì¸ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì°¾ìœ¼ì„¸ìš”. ì°¾ì€ ì •ë³´ë§Œ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ { comment: ë„ˆì˜ ì˜ê²¬, data: [ { doc_id: 1, doc_nm: "", amt: "", update_user: "", update_dt: "" } ] ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${question}\n\ncontext:\n` + context);
				//listQuestion.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'context'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'question'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë¼ì¸ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì°¾ìœ¼ì„¸ìš”. ì°¾ì€ ì •ë³´ë§Œ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ { comment: ë„ˆì˜ ì˜ê²¬, data: [ { doc_id: 1, doc_nm: "", amt: "", update_user: "", update_dt: "" } ] ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${question}\n\ncontext:\n` + context);
			}

			console.log(listQuestion);
			*/

			/**
			const prompt = PromptTemplate.fromTemplate(
				contextText
			)

			const chain = prompt
				.pipe(chatModel)
				.pipe(new StringOutputParser())
			*/

			let listData = [];

			for (let context of chunkContext2()) {
				//const q = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'context'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'question'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ëª¨ë“  ì •ë³´ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ë¼ì¸ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì°¾ìœ¼ì„¸ìš”. ì°¾ì€ ì •ë³´ë§Œ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ { comment: ë„ˆì˜ ì˜ê²¬, data: [ { doc_id: 1, doc_nm: "", amt: "", update_user: "", update_dt: "" } ] ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${question}\n\ncontext:\n${context}`;
				const q = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'context'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'question'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. contextëŠ” csví˜•ì‹ì´ê³  ì²«ë²ˆì§¸ì¤„ì€ ì»¬ëŸ¼ëª…ì´ì•¼. ë°˜ë“œì‹œ ëª¨ë“  ì •ë³´ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ë¼ì¸ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì°¾ìœ¼ì„¸ìš”. ì°¾ì€ ì •ë³´ë§Œ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ { comment: ë„ˆì˜ ì˜ê²¬, data: [ { doc_id: 1, doc_nm: "", amt: "", update_user: "", update_dt: "" } ] ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${question}\n\ncontext:\n${context}`;

				//console.log(q);

				//new HumanMessage
				const input = [
					new HumanMessage({
						content: [
							{
								type: "text",
								text: q,
							},
						],
					}),
				];
				let resp = await chatModel.invoke(input);
				//let resp = await chatModel.invoke(q);
				//let resp = await chatModel.invoke(new HumanMessage(q));

				const respJson = parseResponse(resp);

				//const parsed = JSON.parse(resp.content);
				//const parsed = JSON.parse(resp);
				//console.log(parsed);

				listData.push(...extractJson(respJson, "doc_id,doc_nm"));
			}


			return listData;
		} catch (e) {
			console.log(e);
			//ninegrid.alert(e);
			chatRef.current.add("ai", e);
			//ninegrid.alert(e, null, {"class": "rgb", "animation": "shake", });
		}

		return;
			/**
			for (let q of listQuestion) {
				const responses1 = await chatModel.invoke(q);
				console.log(responses1);
			} */
	/**
			try {
				const responses1 = await chatModel.batch(listQuestion);
				return responses1;
			} catch (error) {
				console.error("ğŸ’¥ ì˜¤ë¥˜ ë°œìƒ:", error);
				return [];
			} */

			/**
			model = ChatOpenAI(temperature=0)
			prompt = PromptTemplate(template="{query}")
			chain = prompt | model | StrOutputParser()

			response = chain.invoke({"query": "í•œêµ­ì˜ ìˆ˜ë„ëŠ”?"})
			print(response)
			ì¶œì²˜: https://rudaks.tistory.com/entry/langchain-StrOutputParser-JsonOutputParser-ì´í•´í•˜ê¸° [[ë£¨ë‹¥ìŠ¤ ë¸”ë¡œê·¸] ì—°ìŠµë§Œì´ ì‚´ê¸¸ì´ë‹¤:í‹°ìŠ¤í† ë¦¬]

			const tmpl = "Tell me a joke about {topic}."
			const prompt = ChatPromptTemplate.fromTemplate(tmpl)
			const chain = prompt.pipe(model)
			const response = await chain.invoke({ topic: "cat" })
			*/

			/**
			const prompt = ChatPromptTemplate.fromTemplate(listQuestion[0])
			const chain = prompt.pipe(chatModel);
			const rrr = await chain.invoke(listQuestion[0]);
			console.log(rrr);
			*/

			const responses = await chatModel.batch(listQuestion);


			responses.forEach((resp, index) => {

				console.log(resp);

				if (resp.startsWith("```json")) resp = resp.replace("```json", "");
				if (resp.endsWith("```")) resp = resp.replace("```", "");

				console.log(resp);

				//const parsed = JSON.parse(resp.content);
				const parsed = JSON.parse(resp);
				console.log(parsed);

				const a = extractJson(parsed, "doc_id,doc_nm");
				console.log(a);
				listData.push(...a);

				/**
				if (Array.isArray(parsed)) {
					listData.push(...parsed); // âœ… ë°°ì—´ì´ë©´ spread operator ì ìš©
				} else {
					listData.push(parsed); // âœ… ë°°ì—´ì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
				} */
			});

			console.log("listData", listData);

			return listData;
	};


	//dotenv.config();
	let [messages, setMessages] = useState<string[]>([]);

	const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
	const googleApiKey = import.meta.env.VITE_GOOGLE_API_KEY;

	//console.log("::::::::", import.meta.env.VITE_OPENAI_API_KEY);
	//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });
	//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });
	//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });
	//const chatModel = new ChatOpenAI({ model: 'gpt-4', apiKey });
	//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });

	//const chatModel = new Ollama({ model: "deepseek-r1:8b" });
	//const chatModel = new Ollama({ model: "llama3.1:8b" });
	let chatModel = null;//new Ollama({ model: "phi4:14b" });
	//const chatModel = new Ollama({ model: "mistral:7b" });

	//console.log(ollama);

	//const chain = loadSummarizationChain(chatModel, { type: "refine" });
	//const chain = loadSummarizationChain(chatModel, { type: "map_reduce" });

	/**
	// âœ… ë©”ëª¨ë¦¬ ì„¤ì • (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)
	const memory = new BufferMemory();
	const conversation = new ConversationChain({
		llm: chatModel,
		memory: memory,
	});
		*/

	useEffect(() => {
		console.log("ğŸ“Œ ìµœì‹  messages ê°’:", messages);
	}, [messages]); // âœ… ìƒíƒœ ë³€ê²½ë  ë•Œë§ˆë‹¤ ì‹¤í–‰

	const textAreaRef = useRef<HTMLTextAreaElement>(null);
	const containerRef = useRef<HTMLDivElement>(null);
	const expandIconRef = useRef<HTMLDivElement>(null);
	const collapseIconRef = useRef<HTMLDivElement>(null);
	const chatDivRef = useRef<HTMLDivElement>(null);
	const menuFilterRef = useRef<HTMLDivElement>(null);
	const menuGeneralRef = useRef<HTMLDivElement>(null);
	const menuSettingRef = useRef<HTMLDivElement>(null);
	const settingsRef = useRef<HTMLDivElement>(null);
	const chatRef = useRef<HTMLDivElement>(null);




	let ing = false;

	const q_BAK = async () => {

		//console.log("===========")

		if (ing) return;

		ing = true;

		const textQ = textAreaRef.current.value;

		if (textQ == "") return;

		setMessages(prevMessages => [...prevMessages, { text: textQ, sender: "me" }]); // âœ… ìµœì‹  ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸

		let listQ = [];

		const l = document.querySelector("nine-grid").data.get();

		//await conversation.call({ input: "ì´ì œë¶€í„° ë‚˜ëŠ” 'ë¶„ì„ë´‡'ì´ë¼ê³  ë¶ˆëŸ¬ì¤˜." });
		//await conversation.call({ input: `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” íšŒì‚¬ì˜ ë§¤ì¶œ ì •ë³´ì•¼. ë¶„ì„ ì˜ í•´ì¤˜.\n\n` });
		//await conversation.call({ input: `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” íšŒì‚¬ì˜ ë§¤ì¶œ ì •ë³´ì•¼. ë¶„ì„ ì˜ í•´ì¤˜.\n\n${contextText}` });

		let contextText = "";

		contextText = `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ê³ , { commnet: ë„ˆì˜ ì˜ê²¬, count: ê´€ë ¨ ë¬¸ì„œ ê±´ìˆ˜, context: JSONí˜•ì‹ì˜ context } í˜•ì‹ì— ë§ì¶”ì–´ì„œ ë‹µë³€í•´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: `;
		//listQ.push(contextText);
		const query = `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. í•œê¸€ë¡œ ë‹µë³€í•´ì¤˜. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ê³ , { commnet: ë„ˆì˜ ì˜ê²¬, count: ê´€ë ¨ ë¬¸ì„œ ê±´ìˆ˜, context: JSONí˜•ì‹ì˜ context } í˜•ì‹ì— ë§ì¶”ì–´ì„œ ë‹µë³€í•´ì¤˜.`;
		listQ.push(query);
		for (let i = 0; i < l.length; i++) {

			const o = l[i];
			contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}`;
			//console.log(i % 50);
			listQ.push(`ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`);

			if ((i != 0 && i % 80 == 0) || i == l.length - 1) {
				//listQ.push(`ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
				//listQ.push(`ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ì°¾ì€ ë¬¸ì„œì˜ ë¬¸ì„œIDëŠ” ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
				//console.log(i, contextText);
				//listQ.push(`ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ê³ , { commnet: ë„ˆì˜ ì˜ê²¬, count: ê´€ë ¨ ë¬¸ì„œ ê±´ìˆ˜, context: JSONí˜•ì‹ì˜ context } í˜•ì‹ì— ë§ì¶”ì–´ì„œ ë‹µë³€í•´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
				//listQ.push(`${contextText}`);

				//contextText = "";
			}
		}

		const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 }); //ë¬¸ì„œë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ spilitter ì´ˆê¸°í™”
		const docs = await textSplitter.createDocuments(listQ);

		//const doc1 = new Document(contextText);
		console.log(docs);

		try {
			const res = await chain.invoke({
				input_documents: docs,
				//question: query,
			});

			console.log(res);
		} catch (error) {
			console.error("âŒ ì˜¤ë¥˜ ë°œìƒ:", error);
		}

		ing = false;
	};

	const q_count = async () => {

		if (ing) return;

		ing = true;

		const textQ = textAreaRef.current.value;

		if (textQ == "") return;

		setMessages(prevMessages => [...prevMessages, { text: textQ, sender: "me" }]); // âœ… ìµœì‹  ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸

		let listQ = [];

		const l = document.querySelector("nine-grid").data.get();

		//await conversation.call({ input: "ì´ì œë¶€í„° ë‚˜ëŠ” 'ë¶„ì„ë´‡'ì´ë¼ê³  ë¶ˆëŸ¬ì¤˜." });
		//await conversation.call({ input: `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” íšŒì‚¬ì˜ ë§¤ì¶œ ì •ë³´ì•¼. ë¶„ì„ ì˜ í•´ì¤˜.\n\n` });
		//await conversation.call({ input: `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” íšŒì‚¬ì˜ ë§¤ì¶œ ì •ë³´ì•¼. ë¶„ì„ ì˜ í•´ì¤˜.\n\n${contextText}` });

		let contextText = "";


		for (let i = 0; i < l.length; i++) {

			const o = l[i];
			contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}`;
			//console.log(i % 50);
			//listQ.push(`ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`);

			if ((i != 0 && i % 800 == 0) || i == l.length - 1) {
				//console.log(contextText);
				listQ.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë°ì´íƒ€ì˜ keyëŠ” "doc_id"ì´ê³ , ê´€ë ¨ëœ "doc_id"ë¥¼ ì•Œë ¤ì¤˜. ë§Œì•½, ê´€ë ¨ë¬¸ì„œê°€ ì—†ìœ¼ë©´ 'ê´€ë ¨ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ë‹µë³€ë‚´ìš©ì€ { "comment": "ë„ˆì˜ ì˜ê²¬", "data": { "doc_id": "ë¬¸ì„œID", "doc_nm": "ë¬¸ì„œëª…"} } í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
				//listQ.push(`ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ì°¾ì•„ì¤˜. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
			}
		}

		//const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 }); //ë¬¸ì„œë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ spilitter ì´ˆê¸°í™”
		//const docs = await textSplitter.createDocuments(listQ);

		//const doc1 = new Document(contextText);
		//console.log(docs);

		//console.log(listQ)

		const responses = await chatModel.batch(listQ);

		let keys = [];
		responses.forEach((resp, index) => {
			//console.log(resp.content);

			const parsed = JSON.parse(resp.content);
			console.log(parsed);

			if (Array.isArray(parsed.data)) {
				keys.push(...parsed.data); // âœ… ë°°ì—´ì´ë©´ spread operator ì ìš©
			} else {
				keys.push(parsed.data); // âœ… ë°°ì—´ì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
			}
		});

		console.log("keys", keys, keys.length);

		const aiMsg = keys.length > 0 ? `ë¬¸ì„œë¥¼ ${keys.length}ê±´ ì°¾ì•˜ìŠµë‹ˆë‹¤.` : "ê´€ë ¨ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.";
		setMessages(prevMessages => [...prevMessages, { text: aiMsg, sender: "ai", data: keys, }]); // âœ… ìµœì‹  ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸

		ing = false;
	};

	/**
	 * const model = new ChatGoogleGenerativeAI({
	 *    modelName: "gemini-pro",
	 *    maxOutputTokens: 2048,
	 * });
	 * const response = await model.invoke(new HumanMessage("Hello world!"));
	 */

	const q = async () => {

		//chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.", [{doc_id:1,doc_nm:"test"},{doc_id:2,doc_nm:"test2"}]);
		//return;
		const question = textAreaRef.current.value.trim();
		if (!question) return;


		if (ing) return;
		ing = true;




		/** setTimeout ì—†ìœ¼ë©´, ë§¥ì—ì„œ í•œê¸€ ì”ìƒì´ ë‚¨ìŒ */
		setTimeout(() => {
			textAreaRef.current.value = "";
		});

		chatRef.current.add("me", question);
		chatRef.current.add("ing", question);
		//chatRef.current.add("ai", "dasdf sfs afsf sdf saf dsfdsafdasfdsafsdfsfadsafas dasdf sfs afsf sdf saf dsfdsafdasfdsafsdfsfadsafas dasdf sfs afsf sdf saf dsfdsafdasfdsafsdfsfadsafas", []);
		/**
		setMessages(prevMessages => [...prevMessages, {text: question, sender: "me", data: null }]);
		//setMessages(prevMessages => [...prevMessages, { text: "...", sender: "ing", data: null }]);

		setMessages(prevMessages => [...prevMessages, { text: "dasdf sfs afsf sdf saf dsfdsafdasfdsafsdfsfadsafas dasdf sfs afsf sdf saf dsfdsafdasfdsafsdfsfadsafas dasdf sfs afsf sdf saf dsfdsafdasfdsafsdfsfadsafas", sender: "ai", data: null }]);
		setMessages(prevMessages => [...prevMessages, { text: "s afsf sdf saf", sender: "ai", data: null }]);
		*/
		//return;

		const arrContext : any[] = await aiSearch(question);

		console.log(arrContext);

		if (arrContext) {
			if (arrContext.length < 1) {
				chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.");
			}
			else {
				let contextText = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´. ì´ì „ì— ë„ˆê°€ ì°¾ì•„ì¤€ ë°ì´íƒ€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ëŠ”ê±°ë‹ˆê¹ ì²« ì¤„ì—ëŠ” "${arrContext.length}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤." ë¼ê³  ë‹µë³€ì„ ë‹¬ì•„ì¤˜.\n\ncontext: `;
				for (const o of arrContext) {
					console.log(o);
					contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
					//contextText += JSON.stringify(o) + "\n";
					//contextText += o + "\n";//JSON.stringify(o) + "\n";//`ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
				}

				console.log(arrContext);

				const prompt = PromptTemplate.fromTemplate(
					contextText
				)

				const chain = prompt
					.pipe(chatModel)
					.pipe(new StringOutputParser())

				const result = await chain.invoke();
				//console.log(result)

				/**
				 setMessages(prevMessages =>
				 prevMessages[prevMessages.length - 1]?.sender === "ing"
				 ? prevMessages.slice(0, -1)
				 : prevMessages
				 );
				 setMessages(prevMessages => [...prevMessages, { text: result, sender: "ai", data: arrContext.map(({ doc_id, doc_nm }) => ({ doc_id, doc_nm })), }]);
				 */
				//chatRef.current.add("ai", result, arrContext.map(({ doc_id, doc_nm }) => ({ doc_id, doc_nm })));
				const grd = document.querySelector("nine-grid");
				chatRef.current.add("ai", result, grd.columns.info(), arrContext);
			}

		}

		ing = false;
	};


	const generateVector = async () => {
		const embeddings = new OllamaEmbeddings({ model: "nomic-embed-text" });

		const jsonData = document.querySelector("nine-grid").data.get();


		jsonData.forEach((item, index) => {
			embeddings.embedQuery(JSON.stringify(item))
				.then(vector => {
					return qdrantClient.upsert("my_collection", {
						points: [{ id: index + 1, vector, payload: item }]
					});
				})
				.then(() => {
					console.log(`âœ… ë°ì´í„° ì—…ì„œíŠ¸ ì™„ë£Œ: ID ${index + 1}`);
				})
				.catch(error => {
					console.error(`âŒ ì˜¤ë¥˜ ë°œìƒ (ID ${index + 1}):`, error);
				});
		});
	}

	const generateFilter = async (query) => {
		const prompt = `ë‹¤ìŒ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ Qdrant í•„í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì¤˜: "${query}"`;

		const response = await chatModel.invoke(prompt);
		//const filterJson = JSON.parse(response.text());
		console.log(response);

		return null;
	}

	const generateQdrantFilter= async (userInput) => {

		//console.log(document.querySelector("nine-grid").body.querySelector(`thead [data-col="6"]`));
		//console.log(document.querySelector("nine-grid").columns.info());

		let colInfo = "";
		document.querySelector("nine-grid").columns.info().forEach(info => {
			colInfo += `- "${info.name}": ${info.desc}, ${info.type}\n`;
		});

		//console.log(colInfo);

		// Qdrant í•„í„°ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
		// ì¤‘ìš”: ì‹¤ì œ ì»¬ë ‰ì…˜ì˜ payload í•„ë“œì™€ ê·¸ ë°ì´í„° íƒ€ì…ì„ ì •í™•íˆ ì•Œë ¤ì¤˜ì•¼ Geminiê°€ ì˜¬ë°”ë¥¸ í•„í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
		const prompt = `
			ìì—°ì–´ ì¿¼ë¦¬ë¥¼ Qdrant í•„í„° JSON ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤.

			Qdrant ì»¬ë ‰ì…˜ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° í•„ë“œì™€ ìœ í˜•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.:
			${colInfo}

			í•„í„° ìƒì„± ê·œì¹™:
			1. ìœ„ì— ì œê³µëœ í•„ë“œë§Œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ìƒˆë¡œìš´ í•„ë“œë¥¼ ë§Œë“¤ì§€ ë§ˆì‹­ì‹œì˜¤.
			2. ì¡°ê±´ì´ ëª…í™•í•˜ê²Œ ì§€ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ëª¨í˜¸í•œ ê²½ìš° í•„í„°ì— í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
			3. AND ì¡°ê±´ì—ëŠ” 'must', OR ì¡°ê±´ì—ëŠ” 'should', NOT ì¡°ê±´ì—ëŠ” 'must_not'ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
			4. ë¬¸ìì—´ ì¼ì¹˜ì—ëŠ” 'match.text'ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
			5. ìˆ«ì ë²”ìœ„ì—ëŠ” 'range.gte', 'range.lte', 'range.gt', 'range.lt'ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
			6. íŠ¹ì • ê°’ì„ í¬í•¨í•˜ëŠ” ë°°ì—´ì—ëŠ” 'contains', 'match.any' ë˜ëŠ” 'match.all'ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
			7. ì¶œë ¥ì€ Qdrant í•„í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìœ íš¨í•œ JSON ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
			8. ì ìš© ê°€ëŠ¥í•œ í•„í„°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ JSON ê°ì²´ì¸ {}ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
			
			ì˜ˆ:
			- "500ë‹¬ëŸ¬ ë¯¸ë§Œì˜ ì „ìì œí’ˆ ì°¾ê¸°" -> {"must": [{"key": "category", "match": {"text": "electronics"}}, {"key": "price", "range": {"lt": 500}}]}
			- "John Doe ë˜ëŠ” Jane Smithì˜ ì±… ë³´ê¸°" -> {"should": [{"key": "author", "match": {"text": "John Doe"}}, {"key": "author", "match": {"text": "Jane Smith"}}]}
			- "ì¬ê³  ìˆëŠ” í’ˆëª©(ì˜ë¥˜ ì œì™¸)" -> {"must": [{"key": "in_stock", "match": {"text": true}}], "must_not": [{"key": "category", "match": {"text": "clothing"}}]}
			- "ë‹¤ìŒì´ í¬í•¨ëœ ì œí’ˆ 'new_arrival' íƒœê·¸" -> {"must": [{"key": "tags", "match": {"text": "new_arrival"}}]}
			- "2020ë…„ ì´í›„ ì¶œíŒëœ ë„ì„œ" -> {"must": [{"key": "published_year", "range": {"gt": 2020}}]}
			
			ì´ì œ ë‹¤ìŒ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë³€í™˜í•´ ë³´ê² ìŠµë‹ˆë‹¤.
			ì‚¬ìš©ì ì¿¼ë¦¬: "${userInput}"
			
			Qdrant í•„í„° JSON:
		`;

		try {
			const response = await chatModel.invoke([
				new SystemMessage("You are a helpful assistant."),
				new HumanMessage(prompt),
			]);

			let filterString = response.content.trim();
			if (filterString.startsWith("```json")) {
				filterString = filterString.replace("```json", "");
				const idx = filterString.indexOf("```");
				if (idx > 0) {
					filterString = filterString.substring(0, idx);
					//console.log(filterString.substring(idx+3));
				}
			}
			//filterString = filterString.replaceAll('"value"', '"text"')
			console.log("Generated Filter String:", filterString);

			// Geminiê°€ JSON ëª¨ë“œë‚˜ Structured Outputì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš°, ì§ì ‘ íŒŒì‹± ì‹œë„
			// ì•ˆì •ì ì¸ JSON íŒŒì‹±ì„ ìœ„í•´ 'JSON Mode' ë˜ëŠ” Function Calling ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥
			// LangChainì˜ SelfQueryRetrieverë¥¼ ì‚¬ìš©í•˜ë©´ ì´ ë¶€ë¶„ì„ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
			try {
				return JSON.parse(filterString);
			} catch (parseError) {
				console.error("Failed to parse filter string as JSON:", parseError);
				console.error("String that failed to parse:", filterString);
				return null; // íŒŒì‹± ì‹¤íŒ¨ ì‹œ null ë°˜í™˜ ë˜ëŠ” ì ì ˆí•œ ì—ëŸ¬ ì²˜ë¦¬
			}

		} catch (error) {
			console.error("Error generating Qdrant filter with Gemini:", error);
			return null;
		}
	}

	/**
	 * Qdrantì—ì„œ í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
	 * @param {string} collectionName ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ì´ë¦„
	 * @param {string} queryText ì‚¬ìš©ìì˜ ì›ë³¸ ì¿¼ë¦¬ (ì„ë² ë”© ìƒì„±ìš©)
	 * @param {object | null} filter Qdrant í•„í„° ê°ì²´
	 * @returns {Promise<Array>} ê²€ìƒ‰ ê²°ê³¼ ë°°ì—´
	 */
	const searchWithQdrantFilter = async (collectionName, queryText, filter) => {
		try {
			// ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (Gemini Embedding ëª¨ë¸ ì‚¬ìš©)
			// LangChainì˜ Embeddings í´ë˜ìŠ¤ ë˜ëŠ” @google/generative-ai SDK ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥
			// ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¥¼ ìœ„í•´ ì„ì‹œë¡œ ë”ë¯¸ ë²¡í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
			// ì‹¤ì œë¡œëŠ” GoogleGenerativeAI.embedContent ë“±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
			// const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
			// const embeddingModel = genAI.get  GenerativeModel({ model: "embedding-001" });
			// const { embedding } = await embeddingModel.embedContent({
			//     content: queryText,
			//     taskType: "retrieval_query",
			// });
			//const queryVector = [0.1, 0.2, 0.3, 0.4, ...Array(764).fill(0)]; // ì‹¤ì œ ì„ë² ë”© ë²¡í„°ë¡œ ëŒ€ì²´
			const embeddings = new OllamaEmbeddings({ model: "nomic-embed-text" });
			const queryVector = await embeddings.embedQuery(queryText);


			console.log(collectionName, filter);

			const searchParams = {
				vector: queryVector,
				limit: 500, // ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
				filter: filter, // Geminiê°€ ìƒì„±í•œ í•„í„° ì ìš©
				with_payload: true, // í˜ì´ë¡œë“œë„ í•¨ê»˜ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •
			};

			//console.log("Qdrant Search Params:", JSON.stringify(searchParams, null, 2));

			const searchResult = await qdrantClient.search(collectionName, searchParams);
			return searchResult;

		} catch (error) {
			console.error("Error during Qdrant search:", error);
			return [];
		}
	}


	const q2 = async () => {

		/**
		let agency_code = ["1111060000","1111065000","1111061500","1111056000","1111058000","1111069000","1111051500","1111067000","1111068000","1111063000","1111055000","1111070000","1111064000","1111053000","1111057000","1111071000","1111054000"];
		agency_code = agency_code.sort();

		console.log(agency_code);

		const g = document.querySelector("nine-grid");
		g.filtering.set({
			"agency_code" : agency_code,
			"reference_month" : ['2025-03-31','2025-04-30',],
		});

		return;
			*/

		//chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.", [{doc_id:1,doc_nm:"test"},{doc_id:2,doc_nm:"test2"}]);
		//return;
		const question = textAreaRef.current.value.trim();
		if (!question) return;

		if (ing) return;
		ing = true;

		/** setTimeout ì—†ìœ¼ë©´, ë§¥ì—ì„œ í•œê¸€ ì”ìƒì´ ë‚¨ìŒ */
		setTimeout(() => {
			textAreaRef.current.value = "";
		});

		chatRef.current.add("me", question);
		chatRef.current.add("ing", question);

		/**
		 * generate vector data
		 */
		//generateVector();

		/**
		const input = [
				new HumanMessage({
					content: [
						{
							type: "text",
							text: question + "\n\nì— í•´ë‹¹í•˜ëŠ” Qdrant",
						},
					],
				}),
			];
		let resp = await chatModel.invoke(input);

		console.log(resp);
		*/

		const isEmptyJson = (obj) => {
			return Object.keys(obj).length === 0 && obj.constructor === Object;
		};

		//const filter = generateQdrantFilter(question);
		const qdrantFilter = await generateQdrantFilter(question);
		let searchResults;

		if (qdrantFilter && !isEmptyJson(qdrantFilter)) {
			/**
			 const embeddings = new OllamaEmbeddings({ model: "nomic-embed-text" });
			 const queryVector = await embeddings.embedQuery(question);

			 const results = await qdrantClient.search("my_collection", {
			 vector: queryVector,
			 limit: 20,
			 filter: filter,
			 });

			 console.log("ğŸ” ê²€ìƒ‰ ê²°ê³¼:", results);
			 */
			console.log("\nSuccessfully generated Qdrant filter:");
			console.log(JSON.stringify(qdrantFilter, null, 2));

			searchResults = await searchWithQdrantFilter("my_collection", question, qdrantFilter);
			console.log("\nQdrant Search Results:", searchResults);

		}
		else {
			//console.log("\nCould not generate a valid Qdrant filter. Performing search without filter.");
			// í•„í„° ìƒì„±ì— ì‹¤íŒ¨í•œ ê²½ìš°, í•„í„° ì—†ì´ ì¼ë°˜ ê²€ìƒ‰ ìˆ˜í–‰ ë˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì¬ì…ë ¥ ìš”ì²­
			//searchResults = await searchWithQdrantFilter("my_collection", question, null);
			//console.log("\nQdrant Search Results (without filter):", searchResults);
		}



		const grd = document.querySelector("nine-grid");

		if (!searchResults || searchResults.length == 0) {
			chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.");
		}
		else if (searchResults.length > 100) {
			chatRef.current.add("ai", `${searchResults.length}ê±´ì˜ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.`, grd.columns.info(), searchResults.map(item => item.payload), grd.dataset.unique);
		}
		else {
			let arr = searchResults.map(item => item.payload);
			let contextText = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´. ì œê³µë  ë°ì´í„°ëŠ” CSV í˜•ì‹ì´ë©°, ì²« ë²ˆì§¸ ì¤„ì€ ì»¬ëŸ¼ëª…ì…ë‹ˆë‹¤. ì´ì „ì— ë„ˆê°€ ì°¾ì•„ì¤€ ë°ì´íƒ€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ëŠ”ê±°ë‹ˆê¹ ì²« ì¤„ì—ëŠ” "${arr.length}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤." ë¼ê³  ë‹µë³€ì„ ë‹¬ì•„ì¤˜.\n\ncontext: `;

			let contextText1 = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ëŠ” ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.

				ì•„ë˜ì— ì œê³µë  ë°ì´í„°ëŠ” CSV í˜•ì‹ì´ë©°, ì²« ë²ˆì§¸ ì¤„ì€ ì»¬ëŸ¼ëª…ì…ë‹ˆë‹¤.

				ì´ ë°ì´í„°ë¥¼ ì² ì €íˆ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
				- ë°ì´í„°ì˜ ì£¼ìš” íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?
				- íŠ¹ì´í•˜ê±°ë‚˜ ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´ì´ ìˆë‚˜ìš”?
				- ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” í•­ëª©(ë˜ëŠ” ê°’)ì€ ë¬´ì—‡ì¸ê°€ìš”?
				- ë°ì´í„°ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ë¬¸ì œì ì´ë‚˜ ê°œì„ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?
				- ê° ë°ì´í„° ë ˆì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°„ëµí•œ ìš”ì•½ ë˜ëŠ” ë¶„ë¥˜ê°€ ê°€ëŠ¥í• ê¹Œìš”?

				ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
				1.  **ì£¼ìš” íŠ¸ë Œë“œ**: ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ìš”ì•½
				2.  **ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´/ì´ìƒì¹˜**: êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…
				3.  **ê°€ì¥ ë¹ˆë²ˆí•œ í•­ëª©**: í•­ëª©ëª…ê³¼ ë¹ˆë„ìˆ˜ë¥¼ í¬í•¨ (í…Œì´ë¸” í˜•ì‹ë„ ê°€ëŠ¥)
				4.  **ê°œì„ ì /ë¬¸ì œì **: í…ìŠ¤íŠ¸ ì„¤ëª…
				5.  **ê° ë ˆì½”ë“œì— ëŒ€í•œ ê°„ëµí•œ ìš”ì•½ ë˜ëŠ” ë¶„ë¥˜**: (ì„ íƒ ì‚¬í•­, í•„ìš”ì‹œ)

				context:\n`;

			grd.columns.info().forEach(info => {
				contextText += `${info.desc}\t`;
			});
			contextText += "\n";

			for (const o of arr) {
				grd.columns.info().forEach(info => {
					contextText += `${o[info.name]}\t`;
				});

				contextText += "\n";
				//contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
			}

			//console.log(contextText);

			const prompt = PromptTemplate.fromTemplate(
				contextText
			)

			const chain = prompt
				.pipe(chatModel)
				.pipe(new StringOutputParser())

			const result = await chain.invoke();

			chatRef.current.add("ai", result, grd.columns.info(), arr, grd.dataset.unique);
		}




		/**
		const arrContext : any[] = await aiSearch(question);

		console.log(arrContext);

		if (arrContext) {
			if (arrContext.length < 1) {
				chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.", arrContext);
			}
			else {
				let contextText = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´. ì´ì „ì— ë„ˆê°€ ì°¾ì•„ì¤€ ë°ì´íƒ€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ëŠ”ê±°ë‹ˆê¹ ì²« ì¤„ì—ëŠ” "${arrContext.length}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤." ë¼ê³  ë‹µë³€ì„ ë‹¬ì•„ì¤˜.\n\ncontext: `;
				for (const o of arrContext) {
					console.log(o);
					contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
				}

				console.log(arrContext);

				const prompt = PromptTemplate.fromTemplate(
					contextText
				)

				const chain = prompt
					.pipe(chatModel)
					.pipe(new StringOutputParser())

				const result = await chain.invoke();

				chatRef.current.add("ai", result, arrContext);
			}

		}
		*/


		ing = false;
	};

	const q3 = async () => {

		/**
		 let agency_code = ["1111060000","1111065000","1111061500","1111056000","1111058000","1111069000","1111051500","1111067000","1111068000","1111063000","1111055000","1111070000","1111064000","1111053000","1111057000","1111071000","1111054000"];
		 agency_code = agency_code.sort();

		 console.log(agency_code);

		 const g = document.querySelector("nine-grid");
		 g.filtering.set({
		 "agency_code" : agency_code,
		 "reference_month" : ['2025-03-31','2025-04-30',],
		 });

		 return;
		 */

			//chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.", [{doc_id:1,doc_nm:"test"},{doc_id:2,doc_nm:"test2"}]);
			//return;
		const question = textAreaRef.current.value.trim();
		if (!question) return;

		if (ing) return;
		ing = true;

		/** setTimeout ì—†ìœ¼ë©´, ë§¥ì—ì„œ í•œê¸€ ì”ìƒì´ ë‚¨ìŒ */
		setTimeout(() => {
			textAreaRef.current.value = "";
		});

		chatRef.current.add("me", question);
		chatRef.current.add("ing", question);

		/**
		 * generate vector data
		 */
		//generateVector();

		/**
		 const input = [
		 new HumanMessage({
		 content: [
		 {
		 type: "text",
		 text: question + "\n\nì— í•´ë‹¹í•˜ëŠ” Qdrant",
		 },
		 ],
		 }),
		 ];
		 let resp = await chatModel.invoke(input);

		 console.log(resp);
		 */

		const isEmptyJson = (obj) => {
			return Object.keys(obj).length === 0 && obj.constructor === Object;
		};

		//const filter = generateQdrantFilter(question);
		const qdrantFilter = await generateQdrantFilter(question);
		let searchResults;

		if (qdrantFilter && !isEmptyJson(qdrantFilter)) {
			/**
			 const embeddings = new OllamaEmbeddings({ model: "nomic-embed-text" });
			 const queryVector = await embeddings.embedQuery(question);

			 const results = await qdrantClient.search("my_collection", {
			 vector: queryVector,
			 limit: 20,
			 filter: filter,
			 });

			 console.log("ğŸ” ê²€ìƒ‰ ê²°ê³¼:", results);
			 */
			console.log("\nSuccessfully generated Qdrant filter:");
			console.log(JSON.stringify(qdrantFilter, null, 2));

			searchResults = await searchWithQdrantFilter("my_collection", question, qdrantFilter);
			console.log("\nQdrant Search Results:", searchResults);

		}
		else {
			//console.log("\nCould not generate a valid Qdrant filter. Performing search without filter.");
			// í•„í„° ìƒì„±ì— ì‹¤íŒ¨í•œ ê²½ìš°, í•„í„° ì—†ì´ ì¼ë°˜ ê²€ìƒ‰ ìˆ˜í–‰ ë˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì¬ì…ë ¥ ìš”ì²­
			//searchResults = await searchWithQdrantFilter("my_collection", question, null);
			//console.log("\nQdrant Search Results (without filter):", searchResults);
		}



		const grd = document.querySelector("nine-grid");

		if (!searchResults || searchResults.length == 0) {
			chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.");
		}
		else if (searchResults.length > 100) {
			chatRef.current.add("ai", `${searchResults.length}ê±´ì˜ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.`, grd.columns.info(), searchResults.map(item => item.payload), grd.dataset.unique);
		}
		else {
			let arr = searchResults.map(item => item.payload);
			let contextText = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´. ì œê³µë  ë°ì´í„°ëŠ” CSV í˜•ì‹ì´ë©°, ì²« ë²ˆì§¸ ì¤„ì€ ì»¬ëŸ¼ëª…ì…ë‹ˆë‹¤. ì´ì „ì— ë„ˆê°€ ì°¾ì•„ì¤€ ë°ì´íƒ€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ëŠ”ê±°ë‹ˆê¹ ì²« ì¤„ì—ëŠ” "${arr.length}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤." ë¼ê³  ë‹µë³€ì„ ë‹¬ì•„ì¤˜.\n\ncontext: `;

			let contextText1 = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ëŠ” ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.

				ì•„ë˜ì— ì œê³µë  ë°ì´í„°ëŠ” CSV í˜•ì‹ì´ë©°, ì²« ë²ˆì§¸ ì¤„ì€ ì»¬ëŸ¼ëª…ì…ë‹ˆë‹¤.

				ì´ ë°ì´í„°ë¥¼ ì² ì €íˆ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
				- ë°ì´í„°ì˜ ì£¼ìš” íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?
				- íŠ¹ì´í•˜ê±°ë‚˜ ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´ì´ ìˆë‚˜ìš”?
				- ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” í•­ëª©(ë˜ëŠ” ê°’)ì€ ë¬´ì—‡ì¸ê°€ìš”?
				- ë°ì´í„°ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ë¬¸ì œì ì´ë‚˜ ê°œì„ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?
				- ê° ë°ì´í„° ë ˆì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°„ëµí•œ ìš”ì•½ ë˜ëŠ” ë¶„ë¥˜ê°€ ê°€ëŠ¥í• ê¹Œìš”?

				ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
				1.  **ì£¼ìš” íŠ¸ë Œë“œ**: ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ìš”ì•½
				2.  **ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´/ì´ìƒì¹˜**: êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…
				3.  **ê°€ì¥ ë¹ˆë²ˆí•œ í•­ëª©**: í•­ëª©ëª…ê³¼ ë¹ˆë„ìˆ˜ë¥¼ í¬í•¨ (í…Œì´ë¸” í˜•ì‹ë„ ê°€ëŠ¥)
				4.  **ê°œì„ ì /ë¬¸ì œì **: í…ìŠ¤íŠ¸ ì„¤ëª…
				5.  **ê° ë ˆì½”ë“œì— ëŒ€í•œ ê°„ëµí•œ ìš”ì•½ ë˜ëŠ” ë¶„ë¥˜**: (ì„ íƒ ì‚¬í•­, í•„ìš”ì‹œ)

				context:\n`;

			grd.columns.info().forEach(info => {
				contextText += `${info.desc}\t`;
			});
			contextText += "\n";

			for (const o of arr) {
				grd.columns.info().forEach(info => {
					contextText += `${o[info.name]}\t`;
				});

				contextText += "\n";
				//contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
			}

			//console.log(contextText);

			const prompt = PromptTemplate.fromTemplate(
				contextText
			)

			const chain = prompt
				.pipe(chatModel)
				.pipe(new StringOutputParser())

			const result = await chain.invoke();

			chatRef.current.add("ai", result, grd.columns.info(), arr, grd.dataset.unique);
		}




		/**
		 const arrContext : any[] = await aiSearch(question);

		 console.log(arrContext);

		 if (arrContext) {
		 if (arrContext.length < 1) {
		 chatRef.current.add("ai", "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.", arrContext);
		 }
		 else {
		 let contextText = `ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ë¶„ì„í•´ì¤˜. ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´. ì´ì „ì— ë„ˆê°€ ì°¾ì•„ì¤€ ë°ì´íƒ€ë¥¼ ë‹¤ì‹œ ë³´ë‚´ëŠ”ê±°ë‹ˆê¹ ì²« ì¤„ì—ëŠ” "${arrContext.length}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤." ë¼ê³  ë‹µë³€ì„ ë‹¬ì•„ì¤˜.\n\ncontext: `;
		 for (const o of arrContext) {
		 console.log(o);
		 contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`;
		 }

		 console.log(arrContext);

		 const prompt = PromptTemplate.fromTemplate(
		 contextText
		 )

		 const chain = prompt
		 .pipe(chatModel)
		 .pipe(new StringOutputParser())

		 const result = await chain.invoke();

		 chatRef.current.add("ai", result, arrContext);
		 }

		 }
		 */


		ing = false;
	};

	const q_1 = async () => {

		if (ing) return;

		ing = true;

		const textQ = textAreaRef.current.value;

		if (textQ == "") return;

		setMessages(prevMessages => [...prevMessages, {text: textQ, sender: "me"}]); // âœ… ìµœì‹  ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸

		let listQ = [];

		const l = document.querySelector("nine-grid").data.get();


		let contextText = "";


		for (let i = 0; i < l.length; i++) {

			const o = l[i];
			contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}`;
			//console.log(i % 50);
			//listQ.push(`ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`);

			if ((i != 0 && i % 80 == 0) || i == l.length - 1) {
				//console.log(contextText);
				listQ.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ì— í•œê¸€ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë§Œì•½, ê´€ë ¨ë¬¸ì„œê°€ ì—†ìœ¼ë©´ 'ê´€ë ¨ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ë‹µë³€ë‚´ìš©ì€ { "comment": "ë„ˆì˜ ì˜ê²¬", "doc_id": "ë¬¸ì„œID" } í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
				//listQ.push(`ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ì°¾ì•„ì¤˜. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
			}
		}

		console.log(listQ.length);

		const responses = await ollama.batch(listQ);



		let keys = [];
		responses.forEach((resp, index) => {
			console.log(resp);
			/**
			const parsed = JSON.parse(resp.content);
			//console.log(parsed);
			if (Array.isArray(parsed.doc_id)) {
				keys.push(...parsed.doc_id); // âœ… ë°°ì—´ì´ë©´ spread operator ì ìš©
			} else {
				keys.push(parsed.doc_id); // âœ… ë°°ì—´ì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
			} */
		});

		/**
		 // âœ… Ollama ëª¨ë¸ ì„¤ì •
		 const model = new Ollama({ model: "deepseek-r1:8b" });
		 console.log(model);
		 //const result = await model.invoke(["human", "Hello, how are you?"]);
		 const result = await model.invoke("Hello, how are you?");
		 console.log(result);
		 */


		const result = await ollama.invoke(["human", "Hello, how are you?"]);
		//const result = await model.invoke("Hello, how are you?");
		console.log(result);
		/**
		const OLLAMA_API_URL = "http://localhost:11434/api/generate";
		const model = "deepseek-r1:8b";
		const prompt = "í•˜ì´";

		try {
			const response = await axios.post(
				OLLAMA_API_URL,
				{
					"model" : model,
					"prompt" : prompt,
				},
				{
					headers: {"Content-Type": "application/json"}, // âœ… JSON í—¤ë” ì¶”ê°€
				}
			);

			console.log("Ollama ì‘ë‹µ:", response.data);
		} catch (error) {
			console.error("Ollama ì‹¤í–‰ ì˜¤ë¥˜:", error);
		}
		*/


		//runOllama("ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ìš”ì•½ì„ í•´ì¤˜.", "deepseek-r1");

// âœ… ì§ˆë¬¸ ì‹¤í–‰
		//async function askOllama() {
			//const response = await llm.call("ì˜¤ëŠ˜ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜.");
			//console.log("ğŸš€ Ollama ì‘ë‹µ:", response);
		//}

		ing = false;
	};


	const q_map_reduce = async () => {

		if (ing) return;

		ing = true;

		const textQ = textAreaRef.current.value;

		if (textQ == "") return;

		setMessages(prevMessages => [...prevMessages, { text: textQ, sender: "me" }]); // âœ… ìµœì‹  ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸

		let listQ = [];

		const l = document.querySelector("nine-grid").data.get();

		//await conversation.call({ input: "ì´ì œë¶€í„° ë‚˜ëŠ” 'ë¶„ì„ë´‡'ì´ë¼ê³  ë¶ˆëŸ¬ì¤˜." });
		//await conversation.call({ input: `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” íšŒì‚¬ì˜ ë§¤ì¶œ ì •ë³´ì•¼. ë¶„ì„ ì˜ í•´ì¤˜.\n\n` });
		//await conversation.call({ input: `ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” íšŒì‚¬ì˜ ë§¤ì¶œ ì •ë³´ì•¼. ë¶„ì„ ì˜ í•´ì¤˜.\n\n${contextText}` });

		let contextText = "";

		//listQ.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë‹µë³€ì€ í•œê¸€ë¡œ í•´ì£¼ì„¸ìš”. ë°ì´íƒ€ì˜ keyëŠ” "doc_id"ì´ê³ , ê´€ë ¨ëœ "doc_id"ë¥¼ ì•Œë ¤ì¤˜. ë§Œì•½, ê´€ë ¨ë¬¸ì„œê°€ ì—†ìœ¼ë©´ 'ê´€ë ¨ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ë‹µë³€ë‚´ìš©ì€ { "comment": "ë„ˆì˜ ì˜ê²¬", "data": { "doc_id": "ë¬¸ì„œID", "doc_nm": "ë¬¸ì„œëª…"} } í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: `);

		for (let i = 0; i < l.length; i++) {

			const o = l[i];
			contextText += `ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}`;
			//console.log(i % 50);
			//listQ.push(`ë¬¸ì„œID: ${o.doc_id}, ë¬¸ì„œëª…: ${o.doc_nm}, ë§¤ì¶œì•¡: ${o.amt}, ìˆ˜ì •ì: ${o.update_user}, ìˆ˜ì •ì¼: ${o.update_dt}\n`);

			if ((i != 0 && i % 800 == 0) || i == l.length - 1) {
				//listQ.push(contextText);



				//console.log(contextText);
				listQ.push(`ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ëŠ” AI ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ì— ë§ëŠ” ë°ì´íƒ€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ë‹µë³€ì€ í•œê¸€ë¡œ í•´ì£¼ì„¸ìš”. ë°ì´íƒ€ì˜ keyëŠ” "doc_id"ì´ê³ , ê´€ë ¨ëœ "doc_id"ë¥¼ ì•Œë ¤ì¤˜. ë§Œì•½, ê´€ë ¨ë¬¸ì„œê°€ ì—†ìœ¼ë©´ 'ê´€ë ¨ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ë‹µë³€ë‚´ìš©ì€ { "comment": "ë„ˆì˜ ì˜ê²¬", "data": { "doc_id": "ë¬¸ì„œID", "doc_nm": "ë¬¸ì„œëª…"} } í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);
				//listQ.push(`ë‚´ê°€ ë³´ë‚´ëŠ” ë°ì´íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´íƒ€ë¥¼ ì°¾ì•„ì¤˜. ì°¾ì€ ë¬¸ì„œ IDë¥¼ ë°°ì—´ë¡œ ë³´ë‚´ì¤˜. ì§ˆë¬¸ë‚´ìš©ì€ "question" í•­ëª©ì´ê³  ë°ì´íƒ€ëŠ” "context" í•­ëª©ì— ìˆì–´.\n\nquestion: ${textQ}\n\ncontext: ${contextText}`);

				contextText = "";
			}
		}

		const chain = loadSummarizationChain(chatModel, { type: "map_reduce" }); //mapReduceë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” loadSummarizationChain ì´ˆê¸°í™”

		const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 }); //ë¬¸ì„œë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ spilitter ì´ˆê¸°í™”
		//const docs = await textSplitter.createDocuments(listQ);
		const docs = await textSplitter.createDocuments(listQ);

		const res = await chain.invoke({
			input_documents: docs,
		}); //chain ì‚¬ìš©

		console.log({ res });

		//const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 }); //ë¬¸ì„œë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ spilitter ì´ˆê¸°í™”
		//const docs = await textSplitter.createDocuments(listQ);

		//const doc1 = new Document(contextText);
		//console.log(docs);

		//console.log(listQ)

		/**
		const responses = await chatModel.batch(listQ);

		let keys = [];
		responses.forEach((resp, index) => {
			//console.log(resp.content);

			const parsed = JSON.parse(resp.content);
			console.log(parsed);

			if (Array.isArray(parsed.data)) {
				keys.push(...parsed.data); // âœ… ë°°ì—´ì´ë©´ spread operator ì ìš©
			} else {
				keys.push(parsed.data); // âœ… ë°°ì—´ì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
			}
		});

		console.log("keys", keys);

		const aiMsg = keys.length > 0 ? `ë¬¸ì„œë¥¼ ${keys.length}ê±´ ì°¾ì•˜ìŠµë‹ˆë‹¤.` : "ê´€ë ¨ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.";
		setMessages(prevMessages => [...prevMessages, { text: aiMsg, sender: "ai", data: keys, }]); // âœ… ìµœì‹  ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸
		*/



		ing = false;
	};

	const changeModel = () => {
		switch (settingsRef.current.server) {
			case "gemini":
				chatModel = new ChatGoogleGenerativeAI({ model: settingsRef.current.model, apiKey: googleApiKey, temperature: 0,});
				break;
			case "openai":
				chatModel = new ChatOpenAI({ model: settingsRef.current.model, apiKey });
				break;
			case "ollama":
				chatModel = new Ollama({ model: settingsRef.current.model });
				break;
		}
		console.log(chatModel);
	};

	useEffect(() => {
		return;

		const handleKeyDown = (e: KeyboardEvent) => {
			if (e.key === "Enter") {
				e.preventDefault();

				const elMenuFilter = containerRef.current.querySelector(".menu-filter");
				const elMenuGeneral = containerRef.current.querySelector(".menu-general");

				if (elMenuFilter.classList.contains("active")) {
					q();
				}
				else if (elMenuFilter.classList.contains("active")) {
					q2();
				}
				else {
					q3();
				}
			}
		}

		if (textAreaRef) {
			textAreaRef.current.addEventListener("keydown", handleKeyDown);
		}



		if (settingsRef) {
			//settingsRef.current.server = "ollama";
			//settingsRef.current.model = "phi4:14b";

			//const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
			//console.log("::::::::", import.meta.env.VITE_OPENAI_API_KEY);
			//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });
			//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });
			//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });
			//const chatModel = new ChatOpenAI({ model: 'gpt-4', apiKey });
			//const chatModel = new ChatOpenAI({ model: 'gpt-3.5-turbo', apiKey });

			//const chatModel = new Ollama({ model: "deepseek-r1:8b" });
			//const chatModel = new Ollama({ model: "llama3.1:8b" });
			//let chatModel = new Ollama({ model: "phi4:14b" });
			//const chatModel = new Ollama({ model: "mistral:7b" });

			changeModel();

			settingsRef.current.addEventListener(settingsRef.current.EVENT.MODEL_CHANGE, (event) => {
				console.log("ğŸ”„ ëª¨ë¸ ë³€ê²½ë¨:", event);
				changeModel();
			});
		}


		const toggleCollapse = () => {
			if (!containerRef.current) return;

			containerRef.current.classList.toggle("collapse");

			if (!containerRef.current.classList.contains("collapse")) {
				// this.#resetAsk();
			}
		};

		collapseIconRef.current.addEventListener("click", toggleCollapse);
		expandIconRef.current.addEventListener("click", toggleCollapse);

		const menuClickHandler = (e) => {
			containerRef.current.querySelectorAll(".menu-icon").forEach(elem => {
				elem.classList.remove("active");
			});

			e.target.closest(".menu-icon").classList.add("active");

			console.log(settingsRef);
			if (e.target.closest(".menu-setting")) {
				settingsRef.current.classList.add("expand");
			}
			else {
				settingsRef.current.classList.remove("expand");
			}
		};

		menuFilterRef.current.addEventListener("click", menuClickHandler);
		menuGeneralRef.current.addEventListener("click", menuClickHandler);
		menuSettingRef.current.addEventListener("click", menuClickHandler);

		//this.classList.add("collapse");

		/**
		this.shadowRoot.querySelector(".icon").addEventListener("click", e => {
			this.classList.toggle("collapse");

			if (!this.classList.contains("collapse")) {
				//this.#resetAsk();
			}
		});

		this.shadowRoot.querySelector(".close").addEventListener("click", e => {
			this.classList.toggle("collapse");
		}); */

		// âœ… ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì œê±°
		return () => {
			if (textAreaRef.current) {
				textAreaRef.current.removeEventListener("keydown", handleKeyDown);
			}
		};
	}, []);


	return (
		<nx-ai-container className="collapse"></nx-ai-container>
	);

	return (
		<div ref={containerRef} className="ai-chat collapse">
			<div className="wrapper">
				<nx-ai-settings ref={settingsRef}></nx-ai-settings>

				<div className="container">

					<div className="head">
						<div className="logo"/>
					</div>
					<nx-ai-chat ref={chatRef}></nx-ai-chat>
					<div className="foot">
						<textarea ref={textAreaRef} name="ask" id="q" name="q" rows="4"
								  placeholder="ë‚˜ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë´..."></textarea>
					</div>
				</div>
				<div className="menu">
					<div ref={collapseIconRef} className="collapse-icon">
						<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
							 viewBox="0 0 16 16">
							<path
								d="M6 8a.5.5 0 0 0 .5.5h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 0 0-.708.708L12.293 7.5H6.5A.5.5 0 0 0 6 8m-2.5 7a.5.5 0 0 1-.5-.5v-13a.5.5 0 0 1 1 0v13a.5.5 0 0 1-.5.5"/>
						</svg>
					</div>

					<div ref={menuFilterRef} className="menu-icon menu-filter">
						<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
							 className="bi bi-funnel-fill" viewBox="0 0 16 16">
							<path
								d="M1.5 1.5A.5.5 0 0 1 2 1h12a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-.128.334L10 8.692V13.5a.5.5 0 0 1-.342.474l-3 1A.5.5 0 0 1 6 14.5V8.692L1.628 3.834A.5.5 0 0 1 1.5 3.5z"/>
						</svg>
					</div>

					<div ref={menuGeneralRef} className="menu-icon menu-general active">
						<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
							 className="bi bi-chat-fill" viewBox="0 0 16 16">
							<path
								d="M8 15c4.418 0 8-3.134 8-7s-3.582-7-8-7-8 3.134-8 7c0 1.76.743 3.37 1.97 4.6-.097 1.016-.417 2.13-.771 2.966-.079.186.074.394.273.362 2.256-.37 3.597-.938 4.18-1.234A9 9 0 0 0 8 15"/>
						</svg>
					</div>

					<div ref={menuGeneralRef} className="menu-icon menu-db">
						<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
							 className="bi bi-chat-fill" viewBox="0 0 16 16">
							<path
								d="M8 15c4.418 0 8-3.134 8-7s-3.582-7-8-7-8 3.134-8 7c0 1.76.743 3.37 1.97 4.6-.097 1.016-.417 2.13-.771 2.966-.079.186.074.394.273.362 2.256-.37 3.597-.938 4.18-1.234A9 9 0 0 0 8 15"/>
						</svg>
					</div>

					<div ref={menuSettingRef} className="menu-icon menu-setting">
						<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
							 className="bi bi-gear-fill" viewBox="0 0 16 16">
							<path
								d="M9.405 1.05c-.413-1.4-2.397-1.4-2.81 0l-.1.34a1.464 1.464 0 0 1-2.105.872l-.31-.17c-1.283-.698-2.686.705-1.987 1.987l.169.311c.446.82.023 1.841-.872 2.105l-.34.1c-1.4.413-1.4 2.397 0 2.81l.34.1a1.464 1.464 0 0 1 .872 2.105l-.17.31c-.698 1.283.705 2.686 1.987 1.987l.311-.169a1.464 1.464 0 0 1 2.105.872l.1.34c.413 1.4 2.397 1.4 2.81 0l.1-.34a1.464 1.464 0 0 1 2.105-.872l.31.17c1.283.698 2.686-.705 1.987-1.987l-.169-.311a1.464 1.464 0 0 1 .872-2.105l.34-.1c1.4-.413 1.4-2.397 0-2.81l-.34-.1a1.464 1.464 0 0 1-.872-2.105l.17-.31c.698-1.283-.705-2.686-1.987-1.987l-.311.169a1.464 1.464 0 0 1-2.105-.872zM8 10.93a2.929 2.929 0 1 1 0-5.86 2.929 2.929 0 0 1 0 5.858z"/>
						</svg>
					</div>
				</div>
			</div>

			<div ref={expandIconRef} className="expand-icon">
				<svg width="32" height="32" fill="green" xmlns="http://www.w3.org/2000/svg" strokeWidth="1.5"
					 className="h-6 w-6"
					 viewBox="-0.17090198558635983 0.482230148717937 41.14235318283891 40.0339509076386">
					<text x="-9999" y="-9999">ChatGPT</text>
					<path
						d="M37.532 16.87a9.963 9.963 0 0 0-.856-8.184 10.078 10.078 0 0 0-10.855-4.835A9.964 9.964 0 0 0 18.306.5a10.079 10.079 0 0 0-9.614 6.977 9.967 9.967 0 0 0-6.664 4.834 10.08 10.08 0 0 0 1.24 11.817 9.965 9.965 0 0 0 .856 8.185 10.079 10.079 0 0 0 10.855 4.835 9.965 9.965 0 0 0 7.516 3.35 10.078 10.078 0 0 0 9.617-6.981 9.967 9.967 0 0 0 6.663-4.834 10.079 10.079 0 0 0-1.243-11.813zM22.498 37.886a7.474 7.474 0 0 1-4.799-1.735c.061-.033.168-.091.237-.134l7.964-4.6a1.294 1.294 0 0 0 .655-1.134V19.054l3.366 1.944a.12.12 0 0 1 .066.092v9.299a7.505 7.505 0 0 1-7.49 7.496zM6.392 31.006a7.471 7.471 0 0 1-.894-5.023c.06.036.162.099.237.141l7.964 4.6a1.297 1.297 0 0 0 1.308 0l9.724-5.614v3.888a.12.12 0 0 1-.048.103l-8.051 4.649a7.504 7.504 0 0 1-10.24-2.744zM4.297 13.62A7.469 7.469 0 0 1 8.2 10.333c0 .068-.004.19-.004.274v9.201a1.294 1.294 0 0 0 .654 1.132l9.723 5.614-3.366 1.944a.12.12 0 0 1-.114.01L7.04 23.856a7.504 7.504 0 0 1-2.743-10.237zm27.658 6.437l-9.724-5.615 3.367-1.943a.121.121 0 0 1 .113-.01l8.052 4.648a7.498 7.498 0 0 1-1.158 13.528v-9.476a1.293 1.293 0 0 0-.65-1.132zm3.35-5.043c-.059-.037-.162-.099-.236-.141l-7.965-4.6a1.298 1.298 0 0 0-1.308 0l-9.723 5.614v-3.888a.12.12 0 0 1 .048-.103l8.05-4.645a7.497 7.497 0 0 1 11.135 7.763zm-21.063 6.929l-3.367-1.944a.12.12 0 0 1-.065-.092v-9.299a7.497 7.497 0 0 1 12.293-5.756 6.94 6.94 0 0 0-.236.134l-7.965 4.6a1.294 1.294 0 0 0-.654 1.132l-.006 11.225zm1.829-3.943l4.33-2.501 4.332 2.5v5l-4.331 2.5-4.331-2.5V18z"/>
				</svg>
			</div>
		</div>
	);
};

export default AiChat;
